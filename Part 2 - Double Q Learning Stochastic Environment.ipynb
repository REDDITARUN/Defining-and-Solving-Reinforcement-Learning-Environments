{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Double Q Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym as gym\n",
    "from gym import spaces\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticFrozenLakeEnv(gym.Env):\n",
    "    metadata = {'render.modes': []}\n",
    "\n",
    "    def __init__(self, gamma=0.9, alpha=0.1, max_timestamp=10):\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.obs_space = spaces.Discrete(16)\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.max_timestamp = max_timestamp\n",
    "        self.timestep = 0\n",
    "\n",
    "        self.state = np.zeros((4, 4))\n",
    "        self.myskater = np.asarray([0, 0])\n",
    "        self.goal_loc = np.asarray([3, 3])\n",
    "        self.gem_loc = [np.asarray([0, 2]), np.asarray([3, 2])]\n",
    "        self.hole_loc = [np.asarray([1, 3]), np.asarray([2, 0])]\n",
    "\n",
    "        self.state[tuple(self.myskater)] = 0.2\n",
    "        self.state[tuple(self.goal_loc)] = 0.8\n",
    "        for pos in self.gem_loc:\n",
    "            self.state[tuple(pos)] = 0.5\n",
    "        for pos in self.hole_loc:\n",
    "            self.state[tuple(pos)] = 0.4\n",
    "\n",
    "        self.prev_state = np.zeros((4, 4))\n",
    "        self.prev_action = None\n",
    "        self.penalty_counter = 0\n",
    "        self.flag_out_grid = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        self.prev_state = np.copy(self.state)\n",
    "        self.prev_action = action\n",
    "        self.flag_out_grid = 0\n",
    "\n",
    "        randomness = [0.35, 0.15, 0.35, 0.15]  # probability for each action\n",
    "        action = np.random.choice(4,p=randomness)\n",
    "\n",
    "        if action == 0:\n",
    "            self.myskater[0] += 1\n",
    "        elif action == 1:\n",
    "            self.myskater[0] -= 1\n",
    "        elif action == 2:\n",
    "            self.myskater[1] += 1\n",
    "        elif action == 3:\n",
    "            self.myskater[1] -= 1\n",
    "\n",
    "        self.myskater = np.clip(self.myskater, 0, 3)\n",
    "\n",
    "        prev_state_positions = np.argwhere(self.prev_state == 0.2)\n",
    "        if len(prev_state_positions) > 0:\n",
    "            if np.array_equal(self.myskater, prev_state_positions[0]):\n",
    "                while action == self.prev_action:\n",
    "                    action = np.random.choice(4, p=randomness)\n",
    "                self.flag_out_grid = 1\n",
    "\n",
    "        self.state = np.zeros((4, 4))\n",
    "        self.state[tuple(self.myskater)] = 0.2\n",
    "        self.state[tuple(self.goal_loc)] = 0.8\n",
    "        for pos in self.gem_loc:\n",
    "            self.state[tuple(pos)] = 0.5\n",
    "        for pos in self.hole_loc:\n",
    "            self.state[tuple(pos)] = 0.4\n",
    "\n",
    "        obs = self.state.flatten()\n",
    "        reward = self.calculate_reward()\n",
    "        penalty = any(np.array_equal(self.myskater, pos) for pos in self.hole_loc)\n",
    "        if penalty:\n",
    "            self.penalty_counter += 1\n",
    "        self.timestep += 1\n",
    "\n",
    "        terminated = True if np.array_equal(self.myskater, self.goal_loc) else self.timestep >= self.max_timestamp\n",
    "        truncated = True if np.any((self.myskater < 0) | (self.myskater > 3)) else False\n",
    "        if terminated or truncated:\n",
    "            self.flag_out_grid=1\n",
    "            self.state = np.copy(self.prev_state) \n",
    "\n",
    "            # Check if there are any positions with a value of 0.2\n",
    "            positions_with_value_0_2 = np.argwhere(self.state == 0.2)\n",
    "\n",
    "            if len(positions_with_value_0_2) > 0:\n",
    "                # Ensure that the index is within bounds\n",
    "                index = np.random.randint(len(positions_with_value_0_2))\n",
    "                self.myagent = positions_with_value_0_2[index]\n",
    "                \n",
    "        info = {}\n",
    "\n",
    "        return self.state.flatten(), reward, terminated, truncated, info\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        self.state = np.zeros((4, 4))\n",
    "        self.myskater = np.asarray([0, 0])\n",
    "        self.state[tuple(self.myskater)] = 0.2\n",
    "        self.state[tuple(self.goal_loc)] = 0.8\n",
    "\n",
    "        for pos in self.gem_loc:\n",
    "            self.state[tuple(pos)] = 0.5\n",
    "        for pos in self.hole_loc:\n",
    "            self.state[tuple(pos)] = 0.4\n",
    "\n",
    "        self.prev_state = np.zeros((4, 4))\n",
    "        self.prev_action = None\n",
    "        self.flag_out_grid = 0 \n",
    "        \n",
    "        obs = self.state.flatten()\n",
    "        self.timestep = 0\n",
    "        info = {}\n",
    "        self.penalty_counter = 0\n",
    "        return obs, info\n",
    "\n",
    "    def calculate_reward(self):\n",
    "        prev_myskateritions = np.argwhere(self.prev_state == 0.2)\n",
    "        if prev_myskateritions.size == 0:\n",
    "            prev_myskaterition = self.myskater\n",
    "        else:\n",
    "            prev_myskaterition = prev_myskateritions[0]\n",
    "\n",
    "        # Calculating distance to goal before and after the step\n",
    "        prev_distance_to_goal = np.linalg.norm(self.goal_loc - prev_myskaterition)\n",
    "        current_distance_to_goal = np.linalg.norm(self.goal_loc - self.myskater)\n",
    "\n",
    "\n",
    "        ## REWARDS SET #############\n",
    "        if np.array_equal(self.myskater, self.goal_loc):\n",
    "            reward = 10  # Positive reward for reaching goal\n",
    "        elif np.array_equal(self.myskater, self.hole_loc[0]):\n",
    "            reward = -5  # negative reward for reaching holes 1\n",
    "        elif np.array_equal(self.myskater, self.hole_loc[1]):\n",
    "            reward = -6   # negative reward for reaching holes 2\n",
    "        elif np.array_equal(self.myskater, self.gem_loc[0]):\n",
    "            reward = 5   # positive reward for reaching gems 1\n",
    "        elif np.array_equal(self.myskater, self.gem_loc[1]):\n",
    "            reward = 6  # positive reward for reaching gems 2\n",
    "        elif current_distance_to_goal < prev_distance_to_goal:\n",
    "            reward = 1  # Positive reward for moving closer to goal\n",
    "        elif current_distance_to_goal > prev_distance_to_goal:\n",
    "            reward = -1  # Negative reward for moving away to goal\n",
    "        else:\n",
    "            reward = -0.1  # Slight negative reward for no change\n",
    "        ##########################\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def get_penalty_count(self):\n",
    "        return self.penalty_counter\n",
    "\n",
    "    def render(self):\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title('Frozen Lake Environment')\n",
    "\n",
    "        # Load and display the background image\n",
    "        background_img = plt.imread('images/frozen_lake.jpg')\n",
    "        ax.imshow(background_img, extent=(-0.5, 3.5, -0.5, 3.5), origin='upper')\n",
    "\n",
    "       \n",
    "        skater_img = plt.imread('images/icons8-skateboard-100.png')\n",
    "        hole_img = plt.imread('images/icons8-hole-100.png')\n",
    "        gem_img = plt.imread('images/icons8-gems-100.png')\n",
    "        goal_img = plt.imread('images/icons8-flag-100.png')\n",
    "        skater_hole_drown_img = plt.imread('images/agent_hole_drown.png')\n",
    "        skater_gem_lottery_img = plt.imread('images/agent_gems_lottery.png')\n",
    "        agent_flag_winner_img = plt.imread('images/agent_flag_winner.png')\n",
    "        agent_grid_cross_img = plt.imread('images/agent_grid_cross.png')\n",
    "\n",
    "        # Plot Skater\n",
    "        myskater = self.myskater\n",
    "        if self.flag_out_grid:\n",
    "            skater_img = agent_grid_cross_img\n",
    "        agent_box = AnnotationBbox(OffsetImage(skater_img, zoom=0.4), myskater, frameon=False)\n",
    "        ax.add_artist(agent_box)\n",
    "\n",
    "        # Plot Holes\n",
    "        for hole_loc in self.hole_loc:\n",
    "            hole_loc = hole_loc\n",
    "            if np.array_equal(self.myskater, hole_loc):\n",
    "                hole_img = skater_hole_drown_img\n",
    "            else:\n",
    "                hole_img = plt.imread('images/icons8-hole-100.png')\n",
    "            rock_box = AnnotationBbox(OffsetImage(hole_img, zoom=0.4), hole_loc, frameon=False)\n",
    "            ax.add_artist(rock_box)\n",
    "\n",
    "        # Plot Gems\n",
    "        for gem_loc in self.gem_loc:\n",
    "            gem_loc = gem_loc\n",
    "            if np.array_equal(self.myskater, gem_loc):\n",
    "                gem_img = skater_gem_lottery_img\n",
    "            else:\n",
    "                gem_img = plt.imread('images/icons8-gems-100.png')\n",
    "            battery_box = AnnotationBbox(OffsetImage(gem_img, zoom=0.4), gem_loc, frameon=False)\n",
    "            ax.add_artist(battery_box)\n",
    "\n",
    "        # Plot goal\n",
    "        goal_loc = self.goal_loc\n",
    "        goal_loc = self.goal_loc\n",
    "        if np.array_equal(self.myskater, goal_loc):\n",
    "            goal_img = agent_flag_winner_img\n",
    "        else:\n",
    "            goal_img = plt.imread('images/icons8-flag-100.png')\n",
    "        goal_box = AnnotationBbox(OffsetImage(goal_img, zoom=0.4), goal_loc, frameon=False)\n",
    "        ax.add_artist(goal_box)\n",
    "\n",
    "        plt.xticks(np.arange(-0.5, 4.5, 1))\n",
    "        plt.yticks(np.arange(-0.5, 4.5, 1))\n",
    "        plt.gca().set_xticklabels(np.arange(-0.5, 4.5, 1))\n",
    "        plt.gca().set_yticklabels(np.arange(-0.5, 4.5, 1))\n",
    "        plt.show()\n",
    "\n",
    "    def obs_space_to_index(self, obs):\n",
    "        myskater = np.argwhere(obs.reshape(4, 4) == 0.2)\n",
    "        if myskater.size == 0:\n",
    "            return 0 \n",
    "        return myskater[0, 0] * 4 + myskater[0, 1]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
